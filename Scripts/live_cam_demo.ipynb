{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Cam Detection with Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
      "  Cloning https://github.com/rcmalli/keras-vggface.git to c:\\users\\massi\\appdata\\local\\temp\\pip-req-build-hi4d9fhs\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\massi\\anaconda3\\envs\\dsim\\lib\\site-packages (from keras-vggface==0.6) (1.16.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\massi\\anaconda3\\envs\\dsim\\lib\\site-packages (from keras-vggface==0.6) (1.3.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\massi\\anaconda3\\envs\\dsim\\lib\\site-packages (from keras-vggface==0.6) (2.9.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\massi\\anaconda3\\envs\\dsim\\lib\\site-packages (from keras-vggface==0.6) (6.2.1)\n",
      "Requirement already satisfied: keras in c:\\users\\massi\\anaconda3\\envs\\dsim\\lib\\site-packages (from keras-vggface==0.6) (2.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\massi\\appdata\\roaming\\python\\python37\\site-packages (from keras-vggface==0.6) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\massi\\anaconda3\\envs\\dsim\\lib\\site-packages (from keras-vggface==0.6) (5.1.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\massi\\anaconda3\\envs\\dsim\\lib\\site-packages (from keras->keras-vggface==0.6) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\massi\\anaconda3\\envs\\dsim\\lib\\site-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
      "Building wheels for collected packages: keras-vggface\n",
      "  Building wheel for keras-vggface (setup.py): started\n",
      "  Building wheel for keras-vggface (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp37-none-any.whl size=8385 sha256=5cbfb79f71ccd352eb114b31d488313813c28b5d0e860bca06ee3d2e75fbcb5d\n",
      "  Stored in directory: C:\\Users\\massi\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-4na__5fs\\wheels\\36\\07\\46\\06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
      "Successfully built keras-vggface\n",
      "Installing collected packages: keras-vggface\n",
      "Successfully installed keras-vggface-0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git 'C:\\Users\\massi\\AppData\\Local\\Temp\\pip-req-build-hi4d9fhs'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/rcmalli/keras-vggface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from cv2 import VideoCapture as cap\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from keras.models import load_model\n",
    "from keras_vggface.utils import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "model = load_model('weights-senet50-full2.best.hdf5')\n",
    "print('Loaded model from disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelling(img, model):\n",
    "    #-- fase di preprocess per l'immagine (to vggface input)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    x = img.astype('float64')\n",
    "    x = preprocess_input(x, version=2)\n",
    "    \n",
    "    #-- predict sul modello pre-trainato\n",
    "    predicted = model.predict(x)\n",
    "    \n",
    "    #if np.max(predicted) >= .5:\n",
    "    #-- acquiszione valore di accuracy\n",
    "    acc = round(np.max(predicted), 3)\n",
    "    \n",
    "    #-- selezione per il labelling\n",
    "    pred = np.argmax(predicted, axis = 1)\n",
    "    if pred == 0:\n",
    "        label = 'Angry'\n",
    "    if pred == 1:\n",
    "        label = 'Disgust'\n",
    "    if pred == 2:\n",
    "        label = 'Fear'\n",
    "    if pred == 3:\n",
    "        label = 'Happy'\n",
    "    if pred == 4:\n",
    "        label = 'Neutral'\n",
    "    if pred == 5:\n",
    "        label = 'Sad'\n",
    "    if pred == 6:\n",
    "        label = 'Surprise'\n",
    "#     else:\n",
    "#         label = 'Unknown'\n",
    "\n",
    "    return label, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(image, model, classifier,\n",
    "           scale_factor = 1.1, minNeighbors = 5,\n",
    "           size = (224,224)):\n",
    "    '''\n",
    "    This function takes in input images and after face detection apply a crop and a resize to that images.\n",
    "    \n",
    "    @params:\n",
    "    from_directory = where to find the photos\n",
    "    to_directory = where to save the photos\n",
    "    classifier = face detector pre-trained (XML file)\n",
    "    size = tuple\n",
    "    color = RGB or BW\n",
    "    init_number = first number to start naming photos\n",
    "    '''\n",
    "    face_cascade = cv.CascadeClassifier(classifier)\n",
    "    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scale_factor, minNeighbors)\n",
    "\n",
    "    if len(faces) == 1:\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi_color = image[y:y+h, x:x+w]\n",
    "            n_img = cv.resize(roi_color, size)\n",
    "            \n",
    "            #-- color B, G, R\n",
    "            color_face = (255,204,0) #azzurro\n",
    "            color_text = (0,153,255) #arancione\n",
    "            rectangle_bgr = (255,204,0) #arancione\n",
    "            \n",
    "            #-- setup font e size per il testo\n",
    "            font = cv.FONT_HERSHEY_DUPLEX\n",
    "            font_scale = 1\n",
    "            \n",
    "            #-- rettangolo face detection\n",
    "            cv.rectangle(image, (x,y), (x+w,y+h), color_face, 3)\n",
    "            #-- labelling (con model)\n",
    "            label, acc = labelling(n_img, model)\n",
    "            #-- preparo la stringa da stampare\n",
    "            string = label + \" - \" + str(acc)\n",
    "            #-- rettangolo per background stringa\n",
    "            (text_width, text_height) = cv.getTextSize(string, font, fontScale=font_scale, thickness=1)[0]\n",
    "            box_coords = ((x-2, y), (x + text_width + 4, y - text_height - 8))\n",
    "            cv.rectangle(image, box_coords[0], box_coords[1], rectangle_bgr, cv.FILLED)\n",
    "            #-- inserimento stringa\n",
    "            cv.putText(image, string, (x,y-5), font, font_scale, color_text, 1)\n",
    "            \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_cam(model, classifier, resolution = (1280, 720), fps = 30, time_sleep = 2):\n",
    "    '''\n",
    "    This function allow to access to pc webcam in order to acquire images of the subject.\n",
    "    \n",
    "    @params:\n",
    "    directory = where to save the captured images\n",
    "    subject = name of the person who is in photo\n",
    "    init_number = first number to start naming photos\n",
    "    counter_limit = if desired, limit the number of photos captured\n",
    "    resolution = (width, height)\n",
    "    fps = Frame Per Second\n",
    "    time_sleep = sleep between two photos\n",
    "    numbered = Bool, necessary in order to apply counter_limit\n",
    "    '''\n",
    "    cam = cv.VideoCapture(0)\n",
    "\n",
    "    cam.set(cv.CAP_PROP_FRAME_WIDTH, resolution[0])\n",
    "    cam.set(cv.CAP_PROP_FRAME_HEIGHT, resolution[1])\n",
    "    cam.set(cv.CAP_PROP_FPS, fps)\n",
    "\n",
    "    cv.namedWindow(\"acquisition window\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        k = cv.waitKey(1)\n",
    "\n",
    "        time.sleep(time_sleep)\n",
    "\n",
    "        detect(frame, model, classifier=classifier, scale_factor = 1.1, minNeighbors = 6)\n",
    "        \n",
    "        text = 'Press ESC to exit from demo...'\n",
    "        cv.putText(frame, text, (10,20), cv.FONT_HERSHEY_DUPLEX, 0.75, (255,255,255), 1)\n",
    "        \n",
    "        cv.imshow(\"acquisition window\", frame)\n",
    "\n",
    "        \n",
    "        if k%256 == 27:\n",
    "            # ESC pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            break\n",
    "        \n",
    "\n",
    "    cam.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "live_cam(time_sleep = 0.01, model = model, classifier = 'haarcascade_frontalface_alt2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
